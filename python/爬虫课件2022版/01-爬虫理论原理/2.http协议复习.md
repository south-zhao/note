# http协议复习

### 学习目标：

```reStructuredText
- 掌握 http以及https的概念和默认端口
- 掌握 url地址的构成
- 掌握 查看网络请求(请求头和响应头)
- 了解 常见的响应状态码
- 理解 浏览器和爬虫爬取的区别
- 了解 爬虫协议
```

------

## 1. http以及https的概念和区别

> HTTPS比HTTP更安全，但是性能更低

- **HTTP**：超文本传输协议，默认端口号是80
  - 超文本：是指超过文本，不仅限于文本；还包括图片、音频、视频等文件
  - 传输协议：是指使用共用约定的固定格式来传递转换成字符串的超文本内容
- **HTTPS**：HTTP + SSL(安全套接字层)，即带有安全套接字层的超本文传输协，默认端口号：443
  - SSL对传输的内容（超文本，也就是请求体或响应体）进行加密
- 可以打开浏览器访问一个url，右键检查，点击net work，点选一个url，查看http协议的形式



## 2.网址的构成

```reStructuredText
地址：https://www.baidu.com/s?ie=UTF-8&wd=python%E7%88%AC%E8%99%AB

协议部分：https://
域名部分：www.baidu.com
路径资源部分：/s
参数部分：?ie=UTF-8&wd=python%E7%88%AC%E8%99%AB
```



## 3.查看网络请求(请求头和响应头)

以chrome浏览器为例，在网页上点击鼠标右键，检查（或者直接F12），选择network，刷新页面，选择ALL下面的第一个链接，这样就可以看到网页的各种请求信息。

<img src="..\img\抓包观察.png"></img>

<img src="..\img\请求头.png"></img>

```reStructuredText
请求头（Request Headers）信息详解：                        请求头重点信息：Cookie，User-Agent，Referer
Accept: text/html,image/*(浏览器可以接收的类型)
Accept-Charset: ISO-8859-1(浏览器可以接收的编码类型)
Accept-Encoding: gzip,compress(浏览器可以接收压缩编码类型)
Accept-Language: en-us,zh-cn(浏览器可以接收的语言和国家类型)
Host: www.it315.org:80(浏览器请求的主机和端口)
If-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT(某个页面缓存时间)
Referer: http://www.it315.org/index.jsp(请求来自于哪个页面)
User-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)(浏览器相关信息)
Cookie：(浏览器暂存服务器发送的信息，个人用户心信息)
Connection: close(1.0)/Keep-Alive(1.1)(HTTP请求的版本的特点)
Date: Tue, 11 Jul 2000 18:23:51 GMT(请求网站的时间)
1234567891011
```

```reStructuredText
响应头（Response Headers）信息详解：
Location: http://www.it315.org/index.jsp(控制浏览器显示哪个页面)
Server:apache tomcat(服务器的类型)
Content-Encoding: gzip(服务器发送的压缩编码方式)
Content-Length: 80(服务器发送显示的字节码长度)
Content-Language: zh-cn(服务器发送内容的语言和国家名)
Content-Type: image/jpeg; charset=UTF-8(服务器发送内容的类型和编码类型)
Last-Modified: Tue, 11 Jul 2000 18:23:51 GMT(服务器最后一次修改的时间)
Refresh: 1;url=http://www.it315.org(控制浏览器1秒钟后转发URL所指向的页面)
Content-Disposition: attachment; filename=aaa.jpg(服务器控制浏览器发下载方式打开文件)
Transfer-Encoding: chunked(服务器分块传递数据到客户端） 
Set-Cookie:SS=Q0=5Lb_nQ; path=/search(服务器发送Cookie相关的信息)
Expires: -1(服务器控制浏览器不要缓存网页，默认是缓存)
Cache-Control: no-cache(服务器控制浏览器不要缓存网页)
Pragma: no-cache(服务器控制浏览器不要缓存网页)  
Connection: close/Keep-Alive(HTTP请求的版本的特点)  
Date: Tue, 11 Jul 2000 18:23:51 GMT(响应网站的时间)
```



## 4. 常见的响应状态码

- `100~199`：表示服务器成功接收部分请求，要求客户端继续提交其余请求才能完成整个处理过程
- `200~299`：表示服务器成功接收请求并已完成整个处理过程。常用200（OK 请求成功）
- `300~399`：为完成请求，客户需进一步细化请求。例如：请求的资源已经移动一个新地址、常用302（所请求的页面已经临时转移至新的url）、307和304（使用缓存资源）
- `400~499`：客户端的请求有错误，常用404（服务器无法找到被请求的页面）、403（服务器拒绝访问，权限不够）
- `500~599`：服务器端出现错误，常用500（请求未完成。服务器遇到不可预知的情况）

我们在学习web知识的时候就已经学过了状态码的相关知识，我们知道这是服务器给我的相关反馈，我们在学习的时候就被教育说应该将真实情况反馈给客户端，但是在爬虫中，可能该站点的开发人员或者运维人员为了阻止数据被爬虫轻易获取，可能在状态码上做手脚，也就是说返回的状态码并不一定就是真实情况，比如:服务器已经识别出你是爬虫，但是为了让你疏忽大意，所以照样返回状态码200，但是响应体重并没有数据。

**所有的状态码都不可信，一切以是否从抓包得到的响应中获取到数据为准**



## 5. 浏览器的运行过程

> 在回顾完http协议后，我们来了解以下浏览器发送http请求的过程

<img src="../img/http发送的过程.png" alt="http发送的过程" style="zoom:50%;" />

浏览器的请求过程：

浏览器获取的内容（elements的内容）包含：url地址对应的响应+js+css+jpg

爬虫会获取：url地址对应的响应

**爬虫获取的内容和elements内容不一样**，进行数据提取的时候，需要根据url地址对应的响应为准



## 爬虫协议（了解）

robots协议：网站通过robots协议，告诉我们搜索引擎哪些页面可以抓取，哪些页面不能抓取，但它仅仅是道德层面上的约束。

[robots协议百度百科]: https://baike.baidu.com/item/robots%E5%8D%8F%E8%AE%AE/2483797?fr=aladdin

