## 建立数据模型



```python
作用：
1：定义数据模型的作用：提前规划好要爬取那些数据。
2：定义数据模型的位置：items.py
```



```python 
"""代码定义"""
import scrapy


class JobInfoItem(scrapy.Item):
    # define the fields for your item here like:
    """工作名称"""
    name = scrapy.Field()
    """发布时间"""
    job_time = scrapy.Field()
    """职位类别"""
    job_type = scrapy.Field()
    """工作地点"""
    job_addr = scrapy.Field()
    """岗位简介"""
    job_data = scrapy.Field()
```



**爬虫文件使用数据模型**

```python
# -*- coding: utf-8 -*-
from fake_useragent import UserAgent
from job_info.items import JobInfoItem
import scrapy, json
ua = UserAgent()


class JobSpider(scrapy.Spider):
    name = 'job'
    allowed_domains = ['tencent.com']
    start_urls = ['https://careers.tencent.com/tencentcareer/api/post/Query?timestamp=1618318847041&countryId=&cityId=&bgIds=&productId=&categoryId=&parentCategoryId=&attrId=&keyword=&pageIndex={}&pageSize=10&language=zh-cn&area=cn']

    def start_requests(self):
        """
        重构起始的请求
        :return:
        """
        headers = {
            'user-agent': ua.chrome
        }

        for page in range(1, 970):
            start_url = self.start_urls[0].format(page)
            yield scrapy.Request(
                url=start_url,
                headers=headers,
            )

    def parse(self, response):
        """
        解析工作列表页
        :param response:
        :return:
        """
        job_list = json.loads(response.body)['Data']['Posts']
        for job in job_list:
            item = JobInfoItem()
            # 工作岗位
            item['name'] = job['RecruitPostName']
            # 发布时间
            item['job_time'] = job['LastUpdateTime']
            # 职位类别
            item['job_type'] = job['CategoryName']
            # 工作地点
            item['job_addr'] = job['LocationName']
            # 岗位简介
            item['job_data'] = job['Responsibility']
            yield item

```





